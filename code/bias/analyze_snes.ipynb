{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"analyze_snes.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLY1b-q0TIcI","executionInfo":{"status":"ok","timestamp":1638858323857,"user_tz":-480,"elapsed":364,"user":{"displayName":"Wee Yi Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16336291919603696387"}},"outputId":"b8e04416-ba29-4a77-9132-1479cae71b68"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"YLY1b-q0TIcI","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"SRiIysv2TKB6","executionInfo":{"status":"ok","timestamp":1638858324268,"user_tz":-480,"elapsed":7,"user":{"displayName":"Wee Yi Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16336291919603696387"}}},"source":["import sys\n","import os\n","os.chdir('/content/drive/MyDrive/NLPProject/bias' )\n","sys.path.append('/content/drive/MyDrive/NLPProject')\n","sys.path.append('/content/drive/MyDrive/NLPProject/bias/')\n","sys.path.append(os.getcwd())"],"id":"SRiIysv2TKB6","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2bfd419","executionInfo":{"status":"ok","timestamp":1638858324675,"user_tz":-480,"elapsed":414,"user":{"displayName":"Wee Yi Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16336291919603696387"}}},"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","import glob\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_theme()\n","\n","steps = ['none', 'neg', 'stop', 'pos', 'stem', 'all', 'pos-neg', 'pos-stop','formal', 'informal', 'pos-neg-stop', 'EMO_INT', 'EMO_LEXI', 'EMO_ATT2_INT', 'EMO_ATT2_LEXI']\n","steps_dic = {'none':'none', 'neg':'neg', 'stop':'stop', 'pos':'pos', 'stem':'stem', 'all':'all', \n","             'pos-neg':'pos+neg', 'pos-stop':'pos+stop', 'formal':'formal', 'informal':'informal',\n","             'pos-neg-stop': 'pos+neg+stop', 'EMO_INT': 'Emotion intensity', 'EMO_LEXI': 'Emotion Lexicon', 'EMO_ATT2_INT': 'Emotion Attention 2 intensity', 'EMO_ATT2_LEXI': 'Emotion Attention 2 Lexicon'}\n","\n","inputtypes = [\"CLAIM_ONLY\", \"EVIDENCE_ONLY\", \"CLAIM_AND_EVIDENCE\"]\n","inputtypes_dic = {\"CLAIM_ONLY\": \"Claim\", \"EVIDENCE_ONLY\": \"Evidence\", \"CLAIM_AND_EVIDENCE\": \"Claim+Evidence\"}\n","# datasets = [\"snes\", \"pomt\"]\n","# datasets_dic = {\"snes\": \"Snopes\", \"pomt\": \"PolitiFact\" }\n","datasets = [\"snes\"]\n","datasets_dic = {\"snes\": \"Snopes\"}\n","# datasets = [\"pomt\"]\n","# datasets_dic = {\"pomt\": \"PolitiFact\"}\n","methods = [\"bert\"]\n","methods_dic = {\"bert\": \"BERT\"}\n","\n","def process_content(content):\n","    val_store = content[0]\n","    test_store = content[1]\n","    other_test_store = content[2]\n","    misc = content[3]\n","\n","    test_remove_top_bottom = content[1][-2]\n","    test_remove_bottom_top = content[1][-1]\n","    other_test_remove_top_bottom = content[2][-2]\n","    other_test_remove_bottom_top = content[2][-1]\n","\n","    val_f1_micro = val_store[0]\n","    val_f1_macro = val_store[1]\n","\n","    test_f1_micro = test_store[0]\n","    test_f1_macro = test_store[1]\n","\n","    other_test_f1_micro = other_test_store[0]\n","    other_test_f1_macro = other_test_store[1]\n","\n","    test_remove_top_bottom_f1_micro = [v[0] for v in test_remove_top_bottom]\n","    test_remove_top_bottom_f1_macro = [v[1] for v in test_remove_top_bottom]\n","\n","    test_remove_bottom_top_f1_micro = [v[0] for v in test_remove_bottom_top]\n","    test_remove_bottom_top_f1_macro = [v[1] for v in test_remove_bottom_top]\n","\n","    other_test_remove_top_bottom_f1_micro = [v[0] for v in other_test_remove_top_bottom]\n","    other_test_remove_top_bottom_macro = [v[1] for v in other_test_remove_top_bottom]\n","\n","    other_test_remove_bottom_top_f1_micro = [v[0] for v in other_test_remove_bottom_top]\n","    other_test_remove_bottom_top_f1_macro = [v[1] for v in other_test_remove_bottom_top]\n","\n","    return val_f1_micro, val_f1_macro, test_f1_micro, test_f1_macro, other_test_f1_micro, other_test_f1_macro, \\\n","           test_remove_top_bottom_f1_micro, test_remove_top_bottom_f1_macro, \\\n","           test_remove_bottom_top_f1_micro, test_remove_bottom_top_f1_macro, \\\n","           other_test_remove_top_bottom_f1_micro, other_test_remove_top_bottom_macro, \\\n","           other_test_remove_bottom_top_f1_micro, other_test_remove_bottom_top_f1_macro\n","\n","def get_results(dataset, inputtype, model, step, other=None):\n","    path = \"./results/\"\n","    # print(f'step: {step}')\n","\n","    filenames = glob.glob(path + \"-\".join([str(v) for v in [model, dataset, inputtype, step]]) + \"*.pkl\")\n","    # print(filenames)\n","    \n","    if other is not None:\n","        filenames = glob.glob(path + \"-\".join([str(v) for v in [other, model, dataset, inputtype, step]]) + \"*.pkl\")\n","\n","    best_val_f1_macro = -np.inf\n","    best_filename = None\n","    best_misc = None\n","    for filename in filenames:\n","        content = pickle.load(open(filename, \"rb\"))\n","        val_f1_macro = (content[0][1]+content[0][0])/2\n","\n","        if val_f1_macro > best_val_f1_macro:\n","            best_filename = filename\n","            best_val_f1_macro = val_f1_macro\n","            best_misc = content[-1]\n","\n","    content = pickle.load(open(best_filename, \"rb\"))\n","#     print(dataset, inputtype, model,)\n","#     print(best_misc)\n","#     print(\"--\")\n","    return process_content(content)\n","\n","def get_test_f1_micro(vals):\n","    return vals[2]\n","\n","def get_test_f1_macro(vals):\n","    return vals[3]\n","\n","def get_other_test_f1_micro(vals):\n","    return vals[4]\n","\n","def get_other_test_f1_macro(vals):\n","    return vals[5]\n","\n","def get_test_remove_top_bottom_f1_micro(vals):\n","    return vals[6]\n","\n","def get_test_remove_top_bottom_f1_macro(vals):\n","    return vals[7]\n","\n","def get_test_remove_bottom_top_f1_micro(vals):\n","    return vals[8]\n","\n","def get_test_remove_bottom_top_f1_macro(vals):\n","    return vals[9]\n","\n","def my_round(val):\n","    return \"{:.3f}\".format(val)\n","\n","#inputtypes = [\"CLAIM_ONLY\", \"EVIDENCE_ONLY\", \"CLAIM_AND_EVIDENCE\"]\n","def plot_snippets(method, step, dataset, resdic):\n","    evid = resdic[step][method][dataset][\"EVIDENCE_ONLY\"]\n","    claim_evid = resdic[step][method][dataset][\"CLAIM_AND_EVIDENCE\"]\n","\n","    evid_original = [get_test_f1_macro(evid)]\n","    claim_evid_original = [get_test_f1_macro(claim_evid)]\n","\n","    evid_top = evid_original + get_test_remove_top_bottom_f1_macro(evid)\n","    evid_bottom = evid_original + get_test_remove_bottom_top_f1_macro(evid)\n","\n","    claim_evid_top = claim_evid_original + get_test_remove_top_bottom_f1_macro(claim_evid)\n","    claim_evid_bottom = claim_evid_original + get_test_remove_bottom_top_f1_macro(claim_evid)\n","\n","    plt.figure(figsize=(5, 3.5))\n","    xs = np.arange(11)\n","    plt.plot(xs, evid_top, \"--*b\", label=\"Evid: remove from top\")\n","    plt.plot(xs, evid_bottom, \"-*b\", label=\"Evid: remove from bottom\")\n","\n","    plt.plot(xs, claim_evid_top, \"--+r\", label=\"Claim+Evid: remove from top\")\n","    plt.plot(xs, claim_evid_bottom, \"-+r\", label=\"Claim+Evid: remove from bottom\")\n","\n","    plt.title(datasets_dic[dataset] + \": \" + methods_dic[method] + \", \" + steps_dic[step])\n","    plt.legend()\n","    plt.xlabel(\"#snippets removed\")\n","    plt.ylabel(\"F1 macro\")\n","    plt.xticks(xs)\n","    plt.tight_layout()\n","    plt.savefig(\"figs/\" + datasets_dic[dataset] + \"_\" + methods_dic[method] + \"_\" + steps_dic[step] + \".pdf\")\n","\n","def print_table(method, step, dataset, resdic): # [method][dataset][t]    \n","    \n","    print(f'\\nmethod: {method} \\t preprocess: {step} \\t dataset: {dataset}')\n","    for inputtype in inputtypes:\n","        line = inputtypes_dic[inputtype]\n","       \n","        for fun in [get_test_f1_micro, get_test_f1_macro, get_other_test_f1_micro, get_other_test_f1_macro]:\n","            line = line + \" & \" + my_round(fun(resdic[step][method][dataset][inputtype]))\n","        line += \" \\\\\\\\\"\n","        print(line)\n","  "],"id":"e2bfd419","execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"5f77cdf9","executionInfo":{"status":"ok","timestamp":1638858324676,"user_tz":-480,"elapsed":10,"user":{"displayName":"Wee Yi Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16336291919603696387"}}},"source":["class vars():\n","    def __init__(self, mode, inputtype):\n","        if mode == \"bow\":\n","            self.dataset = \"snes\"\n","            self.inputtype = inputtype\n","            self.filter_websites = 0\n","            self.model = \"bow\"\n","            self.batchsize = 2\n","            self.eval_per_epoch = 1\n","            self.lr = 0.0001\n","        elif mode == 'lstm':\n","            self.dataset = \"snes\"\n","            self.inputtype = inputtype\n","            self.filter_websites = 0\n","            self.model = \"lstm\"\n","            self.batchsize = 16\n","            self.eval_per_epoch = 1\n","            self.lr = 0.0001\n","            self.lstm_hidden_dim = 128\n","            self.lstm_layers = 2\n","            self.lstm_dropout = 0.1\n","        elif mode == 'bert':\n","            self.dataset = \"snes\"\n","            self.inputtype = inputtype\n","            self.filter_websites = 0\n","            self.model = \"bert\"\n","            self.batchsize = 6\n","            self.eval_per_epoch = 1\n","            self.lr = 0.000003            \n","            \n","\n","mode = 'bert'\n","inputtype = 'CLAIM_ONLY'\n","args = vars(mode, inputtype)"],"id":"5f77cdf9","execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kK5GOmy2USQx","executionInfo":{"status":"ok","timestamp":1638858324677,"user_tz":-480,"elapsed":10,"user":{"displayName":"Wee Yi Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16336291919603696387"}},"outputId":"8cd88a32-1d18-4607-9712-cd20f8514db9"},"source":["!pwd"],"id":"kK5GOmy2USQx","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLPProject/bias\n"]}]},{"cell_type":"code","metadata":{"id":"Ppkiyo58UWku"},"source":["!ls"],"id":"Ppkiyo58UWku","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"76592e93"},"source":["\n","resdic = {}\n","for step in steps:\n","    resdic[step] = {}\n","    for method in methods:\n","        resdic[step][method] = {}\n","        for dataset in datasets:\n","            resdic[step][method][dataset] = {}\n","            for t in inputtypes:\n","                resdic[step][method][dataset][t] = get_results(dataset, t, method, step)\n","\n","for step in steps:\n","    print_table(\"bert\", step, \"snes\", resdic)\n","    plot_snippets(\"bert\", step, \"snes\", resdic)\n","    print('************')\n","    plt.show()\n","    \n","# for step in steps:\n","#     print_table(\"bert\", step, \"pomt\", resdic)\n","#     plot_snippets(\"bert\", step, \"pomt\", resdic)\n","#     print('************')\n","\n","#     plt.show()\n","\n"],"id":"76592e93","execution_count":null,"outputs":[]}]}